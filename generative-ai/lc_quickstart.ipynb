{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtbpMl7pw4uDKNyczAt1VV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleklearn/repo/blob/main/generative-ai/lc_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "IulnkbEYXFoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain openai tiktoken cohere"
      ],
      "metadata": {
        "id": "dM9amLBKd_pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec22dd1f-0539-48c1-c5f1-97be8c47d073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.9/221.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.7/51.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Colab, set OPENAI_API_KEY in Secrets then import to environment cariable\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "g02KRtK6fPRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you're running the notebook on your computer, set OPENAI_API_KEY in your .env file\n",
        "# and install python-dotenv and uncomment code below:\n",
        "\n",
        "# !pip install\n",
        "\n",
        "# from dotenv import load_dotenv\n",
        "\n",
        "# load_dotenv()  # take environment variables from .env"
      ],
      "metadata": {
        "id": "YqBFloQ4fI49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLMs & ChatModels\n"
      ],
      "metadata": {
        "id": "_dIcat31W-ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI()"
      ],
      "metadata": {
        "id": "OImGHOLoeDI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
        "\n",
        "llm.predict(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZtIpNro6fjw5",
        "outputId": "3a1f5ace-8d40-49d7-de5c-e33c9b2ba45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nSocktastic!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI()"
      ],
      "metadata": {
        "id": "Ctmq13wufn7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import HumanMessage\n",
        "\n",
        "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
        "\n",
        "messages = [HumanMessage(content=text)]\n",
        "\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmaMrtpiftpj",
        "outputId": "5ba6e959-02e3-4147-cc55-b04febab9cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='What would be a good company name for a company that makes colorful socks?')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model.predict_messages(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnPZqthXf88g",
        "outputId": "a5da617f-3556-4c39-9f7e-6a3396388c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='ChromaSocks')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt templates"
      ],
      "metadata": {
        "id": "scppBda-XC71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"What is a good name for a company that makes {product}?\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw4bTchxW_uq",
        "outputId": "a86a1f08-6b2e-40c7-b6d3-0831bff09aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['product'], template='What is a good name for a company that makes {product}?')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.format(product='colorful socks')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Cuul46bagaWm",
        "outputId": "5c65768e-bcbb-4262-b68d-00411dd912d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is a good name for a company that makes colorful socks?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "\n",
        "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
        "\n",
        "human_template = \"{text}\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_template),\n",
        "    (\"human\", human_template),\n",
        "])\n",
        "\n",
        "chat_prompt\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd9obnLogk4i",
        "outputId": "2526117d-0c2d-4426-9c10-3581955973aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['input_language', 'output_language', 'text'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input_language', 'output_language'], template='You are a helpful assistant that translates {input_language} to {output_language}.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt.format_messages(input_language=\"English\",\n",
        "                            output_language=\"French\",\n",
        "                            text=\"I love programming.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3r0MDRChL80",
        "outputId": "79a4690d-ca60-482f-aed7-5c3984c31940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are a helpful assistant that translates English to French.'),\n",
              " HumanMessage(content='I love programming.')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain & Chat Chain"
      ],
      "metadata": {
        "id": "3LGkp01_YHYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm\n",
        "\n",
        "chain.invoke({\"product\": \"colorful socks\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WEHa7T-nYIbF",
        "outputId": "b2658839-dc52-44c5-b619-71d0eabb9f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nSocktastic!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_chain = chat_prompt | chat_model\n",
        "\n",
        "chat_chain.invoke({\"input_language\": \"English\",\n",
        "              \"output_language\": \"French\",\n",
        "              \"text\": \"I love programming.\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g0aOrh9hthi",
        "outputId": "c74f24f1-acfd-437c-c24b-a198c5a6eeea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"J'adore programmer.\")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output parsers"
      ],
      "metadata": {
        "id": "dbkwsm3GYMty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import BaseOutputParser\n",
        "\n",
        "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
        "  \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
        "\n",
        "  def parse(self, text: str):\n",
        "      \"\"\"Parse the output of an LLM call.\"\"\"\n",
        "      return text.strip().split(\", \")\n"
      ],
      "metadata": {
        "id": "uCqm1E-LYNw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CommaSeparatedListOutputParser().parse(\"hi, bye\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5cC8Ow0m_8m",
        "outputId": "66a5f556-baf1-4789-a9e8-f7b7b7b12f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', 'bye']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
        "A user will pass in a category, and you should generate 5 objects in that\n",
        "category in a comma separated list.\n",
        "\n",
        "ONLY return a comma separated list, and nothing more.\"\"\"\n",
        "\n",
        "human_template = \"{text}\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_template),\n",
        "    (\"human\", human_template),\n",
        "])\n",
        "\n",
        "chain = chat_prompt | chat_model | CommaSeparatedListOutputParser()\n",
        "\n",
        "chain.invoke({\"text\": \"colors\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mk0RaAtnENX",
        "outputId": "fa2ad500-9ee0-4b1e-cc50-d47a0c7c30c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['red', 'blue', 'green', 'yellow', 'orange']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}